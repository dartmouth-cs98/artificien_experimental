{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning - Model Centric MNIST Example: Train FL Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the \"[01-Create Plan](../model-centric/02-ExecutePlan.ipynb)\" notebook we created the model, training plan, and averaging plan, and then hosted all of them in PyGrid.\n",
    "\n",
    "Such hosted FL model can be now trained using client libraries, SwiftSyft, KotlinSyft, syft.js.\n",
    "\n",
    "In this notebook, we'll use FL Client included in the PySyft to do the training.\n",
    "\n",
    "### Credits:\n",
    "- Original authors: \n",
    "\n",
    " - Vova Manannikov - Github: [@vvmnnnkv](https://github.com/vvmnnnkv)\n",
    "\n",
    "\n",
    "- Reviewers: \n",
    " - Patrick Cason - Github: [@cereallcerny](https://github.com/cereallarceny)\n",
    "\n",
    "\n",
    "- New Content tested and enriched by: \n",
    " - Juan M. Aunon - Twitter: [@jm_aunon](https://twitter.com/jm_aunon) - Github: [@jmaunon](https://github.com/jmaunon)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch as th\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import urllib3\n",
    "import time\n",
    "\n",
    "import syft as sy\n",
    "from syft.federated.fl_client import FLClient\n",
    "from syft.federated.fl_job import FLJob\n",
    "from syft.grid.clients.model_centric_fl_client import ModelCentricFLClient\n",
    "\n",
    "urllib3.disable_warnings()\n",
    "sy.make_hook(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_key = \"\"\"\n",
    "-----BEGIN RSA PRIVATE KEY-----\n",
    "MIIEowIBAAKCAQEAzQMcI09qonB9OZT20X3Z/oigSmybR2xfBQ1YJ1oSjQ3YgV+G\n",
    "FUuhEsGDgqt0rok9BreT4toHqniFixddncTHg7EJzU79KZelk2m9I2sEsKUqEsEF\n",
    "lMpkk9qkPHhJB5AQoClOijee7UNOF4yu3HYvGFphwwh4TNJXxkCg69/RsvPBIPi2\n",
    "9vXFQzFE7cbN6jSxiCtVrpt/w06jJUsEYgNVQhUFABDyWN4h/67M1eArGA540vyd\n",
    "kYdSIEQdknKHjPW62n4dvqDWxtnK0HyChsB+LzmjEnjTJqUzr7kM9Rzq3BY01DNi\n",
    "TVcB2G8t/jICL+TegMGU08ANMKiDfSMGtpz3ZQIDAQABAoIBAD+xbKeHv+BxxGYE\n",
    "Yt5ZFEYhGnOk5GU/RRIjwDSRplvOZmpjTBwHoCZcmsgZDqo/FwekNzzuch1DTnIV\n",
    "M0+V2EqQ0TPJC5xFcfqnikybrhxXZAfpkhtU+gR5lDb5Q+8mkhPAYZdNioG6PGPS\n",
    "oGz8BsuxINhgJEfxvbVpVNWTdun6hLOAMZaH3DHgi0uyTBg8ofARoZP5RIbHwW+D\n",
    "p+5vd9x/x7tByu76nd2UbMp3yqomlB5jQktqyilexCIknEnfb3i/9jqFv8qVE5P6\n",
    "e3jdYoJY+FoomWhqEvtfPpmUFTY5lx4EERCb1qhWG3a7sVBqTwO6jJJBsxy3RLIS\n",
    "Ic0qZcECgYEA6GsBP11a2T4InZ7cixd5qwSeznOFCzfDVvVNI8KUw+n4DOPndpao\n",
    "TUskWOpoV8MyiEGdQHgmTOgGaCXN7bC0ERembK0J64FI3TdKKg0v5nKa7xHb7Qcv\n",
    "t9ccrDZVn4y/Yk5PCqjNWTR3/wDR88XouzIGaWkGlili5IJqdLEvPvUCgYEA4dA+\n",
    "5MNEQmNFezyWs//FS6G3lTRWgjlWg2E6BXXvkEag6G5SBD31v3q9JIjs+sYdOmwj\n",
    "kfkQrxEtbs173xgYWzcDG1FI796LTlJ/YzuoKZml8vEF3T8C4Bkbl6qj9DZljb2j\n",
    "ehjTv5jA256sSUEqOa/mtNFUbFlBjgOZh3TCsLECgYAc701tdRLdXuK1tNRiIJ8O\n",
    "Enou26Thm6SfC9T5sbzRkyxFdo4XbnQvgz5YL36kBnIhEoIgR5UFGBHMH4C+qbQR\n",
    "OK+IchZ9ElBe8gYyrAedmgD96GxH2xAuxAIW0oDgZyZgd71RZ2iBRY322kRJJAdw\n",
    "Xq77qo6eXTKpni7grjpijQKBgDHWRAs5DVeZkTwhoyEW0fRfPKUxZ+ZVwUI9sxCB\n",
    "dt3guKKTtoY5JoOcEyJ9FdBC6TB7rV4KGiSJJf3OXAhgyP9YpNbimbZW52fhzTuZ\n",
    "bwO/ZWC40RKDVZ8f63cNsiGz37XopKvNzu36SJYv7tY8C5WvvLsrd/ZxvIYbRUcf\n",
    "/dgBAoGBAMdR5DXBcOWk3+KyEHXw2qwWcGXyzxtca5SRNLPR2uXvrBYXbhFB/PVj\n",
    "h3rGBsiZbnIvSnSIE+8fFe6MshTl2Qxzw+F2WV3OhhZLLtBnN5qqeSe9PdHLHm49\n",
    "XDce6NV2D1mQLBe8648OI5CScQENuRGxF2/h9igeR4oRRsM1gzJN\n",
    "-----END RSA PRIVATE KEY-----\n",
    "\"\"\".strip()\n",
    "\n",
    "public_key = \"\"\"\n",
    "-----BEGIN PUBLIC KEY-----\n",
    "MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAzQMcI09qonB9OZT20X3Z\n",
    "/oigSmybR2xfBQ1YJ1oSjQ3YgV+GFUuhEsGDgqt0rok9BreT4toHqniFixddncTH\n",
    "g7EJzU79KZelk2m9I2sEsKUqEsEFlMpkk9qkPHhJB5AQoClOijee7UNOF4yu3HYv\n",
    "GFphwwh4TNJXxkCg69/RsvPBIPi29vXFQzFE7cbN6jSxiCtVrpt/w06jJUsEYgNV\n",
    "QhUFABDyWN4h/67M1eArGA540vydkYdSIEQdknKHjPW62n4dvqDWxtnK0HyChsB+\n",
    "LzmjEnjTJqUzr7kM9Rzq3BY01DNiTVcB2G8t/jICL+TegMGU08ANMKiDfSMGtpz3\n",
    "ZQIDAQAB\n",
    "-----END PUBLIC KEY-----\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating authentication token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.e30.Cn_0cSjCw1QKtcYDx_mYN_q9jO2KkpcUoiVbILmKVB4LUCQvZ7YeuyQ51r9h3562KQoSas_ehbjpz2dw1Dk24hQEoN6ObGxfJDOlemF5flvLO_sqAHJDGGE24JRE4lIAXRK6aGyy4f4kmlICL6wG8sGSpSrkZlrFLOVRJckTptgaiOTIm5Udfmi45NljPBQKVpqXFSmmb3dRy_e8g3l5eBVFLgrBhKPQ1VbNfRK712KlQWs7jJ31fGpW2NxMloO1qcd6rux48quivzQBCvyK8PV5Sqrfw_OMOoNLcSvzePDcZXa2nPHSu3qQIikUdZIeCnkJX-w0t8uEFG3DfH1fVA\n"
     ]
    }
   ],
   "source": [
    "import jwt\n",
    "auth_token = jwt.encode({}, private_key, algorithm='RS256').decode('ascii')\n",
    "\n",
    "print(auth_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define `on_accepted`, `on_rejected`, `on_error` handlers.\n",
    "\n",
    "The main training loop is located inside `on_accepted` routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cycles_log = []\n",
    "status = {\n",
    "    \"ended\": False\n",
    "}\n",
    "\n",
    "# Called when client is accepted into FL cycle\n",
    "def on_accepted(job: FLJob):\n",
    "    print(f\"Accepted into cycle {len(cycles_log) + 1}!\")\n",
    "\n",
    "    cycle_params = job.client_config\n",
    "    batch_size = cycle_params[\"batch_size\"]\n",
    "    lr = cycle_params[\"lr\"]\n",
    "    max_updates = cycle_params[\"max_updates\"]\n",
    "\n",
    "    mnist_dataset = th.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    training_plan = job.plans[\"training_plan\"]\n",
    "    model_params = job.model.tensors()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(mnist_dataset):\n",
    "        X = X.view(batch_size, -1)\n",
    "        y_oh = th.nn.functional.one_hot(y, 10)\n",
    "        loss, acc, *model_params = training_plan.torchscript(\n",
    "            X, y_oh, th.tensor(batch_size), th.tensor(lr), model_params\n",
    "        )\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(acc.item())\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(\"Batch %d, loss: %f, accuracy: %f\" % (batch_idx, loss, acc))\n",
    "        if batch_idx >= max_updates:\n",
    "            break\n",
    "\n",
    "    job.report(model_params)\n",
    "    # Save losses/accuracies from cycle\n",
    "    cycles_log.append((losses, accuracies))\n",
    "\n",
    "# Called when the client is rejected from cycle\n",
    "def on_rejected(job: FLJob, timeout):\n",
    "    if timeout is None:\n",
    "        print(f\"Rejected from cycle without timeout (this means FL training is done)\")\n",
    "    else:\n",
    "        print(f\"Rejected from cycle with timeout: {timeout}\")\n",
    "    status[\"ended\"] = True\n",
    "\n",
    "# Called when error occured\n",
    "def on_error(job: FLJob, error: Exception):\n",
    "    print(f\"Error: {error}\")\n",
    "    status[\"ended\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5 \n",
    "mnist_dataset = th.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We use same PyGrid Node where the model was hosted, the model name/version of hosted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# PyGrid Node address\n",
    "gridAddress = \"ws://alice:5000\"\n",
    "\n",
    "# Hosted model name/version\n",
    "model_name = \"mnist\"\n",
    "model_version = \"1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define routine that creates FL client and starts the FL process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.grid_worker.get_connection_speed(client.worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_job(self, model_name, model_version) -> FLJob:\n",
    "        if self.worker_id is None:\n",
    "            auth_response = self.grid_worker.authenticate(\n",
    "                self.auth_token, model_name, model_version\n",
    "            )\n",
    "            self.worker_id = auth_response[\"data\"][\"worker_id\"]\n",
    "\n",
    "        job = FLJob(\n",
    "            fl_client=self,\n",
    "            grid_worker=self.grid_worker,\n",
    "            model_name=model_name,\n",
    "            model_version=model_version,\n",
    "        )\n",
    "        return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_and_run_cycle():\n",
    "    client = FLClient(url=gridAddress, auth_token=auth_token, verbose=True)\n",
    "    client.worker_id = client.grid_worker.authenticate(client.auth_token,model_name,model_version)[\"data\"][\"worker_id\"]\n",
    "    job = client.new_job(model_name, model_version)\n",
    "\n",
    "    # Set event handlers\n",
    "    job.add_listener(job.EVENT_ACCEPTED, on_accepted)\n",
    "    job.add_listener(job.EVENT_REJECTED, on_rejected)\n",
    "    job.add_listener(job.EVENT_ERROR, on_error)\n",
    "\n",
    "    # Shoot!\n",
    "    job.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we're ready to start FL training.\n",
    "\n",
    "We're going to run multiple \"workers\" until the FL model is fully done and see the progress.\n",
    "\n",
    "As we create & authenticate new client each time,\n",
    "this emulates multiple different workers requesting a cycle and working on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while not status[\"ended\"]:\n",
    "    create_client_and_run_cycle()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's plot loss and accuracy statistics recorded from each worker.\n",
    "Each such worker's statistics is drawn with different color.\n",
    "\n",
    "It's visible that loss/accuracy improvement occurs after each `max_diffs` reports to PyGrid,\n",
    "because PyGrid updates the model and creates new checkpoint after\n",
    "receiving `max_diffs` updates from FL clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(10, 10))\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "offset = 0\n",
    "for i, cycle_log in enumerate(cycles_log):\n",
    "    losses, accuracies = cycle_log\n",
    "    x = range(offset, offset + len(losses))\n",
    "    axs[0].plot(x, losses)\n",
    "    axs[1].plot(x, accuracies)\n",
    "    offset += len(losses)\n",
    "    print(f\"Cycle {i + 1}:\\tLoss: {np.mean(losses)}\\tAcc: {np.mean(accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysyft",
   "language": "python",
   "name": "pysyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
