{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pysyft/bin/python: No module named conda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m conda install jwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler\n",
    "\n",
    "import numpy as np\n",
    "import urllib3\n",
    "import time\n",
    "\n",
    "import syft as sy\n",
    "from syft.federated.fl_client import FLClient\n",
    "from syft.federated.fl_job import FLJob\n",
    "from syft.grid.clients.model_centric_fl_client import ModelCentricFLClient\n",
    "import syft.grid\n",
    "\n",
    "urllib3.disable_warnings()\n",
    "sy.make_hook(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_key = \"\"\"\n",
    "-----BEGIN RSA PRIVATE KEY-----\n",
    "MIIEowIBAAKCAQEAzQMcI09qonB9OZT20X3Z/oigSmybR2xfBQ1YJ1oSjQ3YgV+G\n",
    "FUuhEsGDgqt0rok9BreT4toHqniFixddncTHg7EJzU79KZelk2m9I2sEsKUqEsEF\n",
    "lMpkk9qkPHhJB5AQoClOijee7UNOF4yu3HYvGFphwwh4TNJXxkCg69/RsvPBIPi2\n",
    "9vXFQzFE7cbN6jSxiCtVrpt/w06jJUsEYgNVQhUFABDyWN4h/67M1eArGA540vyd\n",
    "kYdSIEQdknKHjPW62n4dvqDWxtnK0HyChsB+LzmjEnjTJqUzr7kM9Rzq3BY01DNi\n",
    "TVcB2G8t/jICL+TegMGU08ANMKiDfSMGtpz3ZQIDAQABAoIBAD+xbKeHv+BxxGYE\n",
    "Yt5ZFEYhGnOk5GU/RRIjwDSRplvOZmpjTBwHoCZcmsgZDqo/FwekNzzuch1DTnIV\n",
    "M0+V2EqQ0TPJC5xFcfqnikybrhxXZAfpkhtU+gR5lDb5Q+8mkhPAYZdNioG6PGPS\n",
    "oGz8BsuxINhgJEfxvbVpVNWTdun6hLOAMZaH3DHgi0uyTBg8ofARoZP5RIbHwW+D\n",
    "p+5vd9x/x7tByu76nd2UbMp3yqomlB5jQktqyilexCIknEnfb3i/9jqFv8qVE5P6\n",
    "e3jdYoJY+FoomWhqEvtfPpmUFTY5lx4EERCb1qhWG3a7sVBqTwO6jJJBsxy3RLIS\n",
    "Ic0qZcECgYEA6GsBP11a2T4InZ7cixd5qwSeznOFCzfDVvVNI8KUw+n4DOPndpao\n",
    "TUskWOpoV8MyiEGdQHgmTOgGaCXN7bC0ERembK0J64FI3TdKKg0v5nKa7xHb7Qcv\n",
    "t9ccrDZVn4y/Yk5PCqjNWTR3/wDR88XouzIGaWkGlili5IJqdLEvPvUCgYEA4dA+\n",
    "5MNEQmNFezyWs//FS6G3lTRWgjlWg2E6BXXvkEag6G5SBD31v3q9JIjs+sYdOmwj\n",
    "kfkQrxEtbs173xgYWzcDG1FI796LTlJ/YzuoKZml8vEF3T8C4Bkbl6qj9DZljb2j\n",
    "ehjTv5jA256sSUEqOa/mtNFUbFlBjgOZh3TCsLECgYAc701tdRLdXuK1tNRiIJ8O\n",
    "Enou26Thm6SfC9T5sbzRkyxFdo4XbnQvgz5YL36kBnIhEoIgR5UFGBHMH4C+qbQR\n",
    "OK+IchZ9ElBe8gYyrAedmgD96GxH2xAuxAIW0oDgZyZgd71RZ2iBRY322kRJJAdw\n",
    "Xq77qo6eXTKpni7grjpijQKBgDHWRAs5DVeZkTwhoyEW0fRfPKUxZ+ZVwUI9sxCB\n",
    "dt3guKKTtoY5JoOcEyJ9FdBC6TB7rV4KGiSJJf3OXAhgyP9YpNbimbZW52fhzTuZ\n",
    "bwO/ZWC40RKDVZ8f63cNsiGz37XopKvNzu36SJYv7tY8C5WvvLsrd/ZxvIYbRUcf\n",
    "/dgBAoGBAMdR5DXBcOWk3+KyEHXw2qwWcGXyzxtca5SRNLPR2uXvrBYXbhFB/PVj\n",
    "h3rGBsiZbnIvSnSIE+8fFe6MshTl2Qxzw+F2WV3OhhZLLtBnN5qqeSe9PdHLHm49\n",
    "XDce6NV2D1mQLBe8648OI5CScQENuRGxF2/h9igeR4oRRsM1gzJN\n",
    "-----END RSA PRIVATE KEY-----\n",
    "\"\"\".strip()\n",
    "\n",
    "public_key = \"\"\"\n",
    "-----BEGIN PUBLIC KEY-----\n",
    "MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAzQMcI09qonB9OZT20X3Z\n",
    "/oigSmybR2xfBQ1YJ1oSjQ3YgV+GFUuhEsGDgqt0rok9BreT4toHqniFixddncTH\n",
    "g7EJzU79KZelk2m9I2sEsKUqEsEFlMpkk9qkPHhJB5AQoClOijee7UNOF4yu3HYv\n",
    "GFphwwh4TNJXxkCg69/RsvPBIPi29vXFQzFE7cbN6jSxiCtVrpt/w06jJUsEYgNV\n",
    "QhUFABDyWN4h/67M1eArGA540vydkYdSIEQdknKHjPW62n4dvqDWxtnK0HyChsB+\n",
    "LzmjEnjTJqUzr7kM9Rzq3BY01DNiTVcB2G8t/jICL+TegMGU08ANMKiDfSMGtpz3\n",
    "ZQIDAQAB\n",
    "-----END PUBLIC KEY-----\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.e30.Cn_0cSjCw1QKtcYDx_mYN_q9jO2KkpcUoiVbILmKVB4LUCQvZ7YeuyQ51r9h3562KQoSas_ehbjpz2dw1Dk24hQEoN6ObGxfJDOlemF5flvLO_sqAHJDGGE24JRE4lIAXRK6aGyy4f4kmlICL6wG8sGSpSrkZlrFLOVRJckTptgaiOTIm5Udfmi45NljPBQKVpqXFSmmb3dRy_e8g3l5eBVFLgrBhKPQ1VbNfRK712KlQWs7jJ31fGpW2NxMloO1qcd6rux48quivzQBCvyK8PV5Sqrfw_OMOoNLcSvzePDcZXa2nPHSu3qQIikUdZIeCnkJX-w0t8uEFG3DfH1fVA\n"
     ]
    }
   ],
   "source": [
    "import jwt\n",
    "auth_token = jwt.encode({}, private_key, algorithm='RS256').decode('ascii')\n",
    "\n",
    "print(auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.dataframe.iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('testdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['sex', 'blood_type', 'height', 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycles_log = []\n",
    "status = {\n",
    "    \"ended\": False\n",
    "}\n",
    "\n",
    "# Called when client is accepted into FL cycle\n",
    "def on_accepted(job: FLJob):\n",
    "    print(f\"Accepted into cycle {len(cycles_log) + 1}!\")\n",
    "\n",
    "    cycle_params = job.client_config\n",
    "    batch_size = cycle_params[\"batch_size\"]\n",
    "    print(batch_size)\n",
    "    lr = cycle_params[\"lr\"]\n",
    "    max_updates = cycle_params[\"max_updates\"]\n",
    "    \n",
    "    health_data = DataLoader(data_dict, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "    \n",
    "    training_plan = job.plans[\"training_plan\"]\n",
    "    model_params = job.model.tensors()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(health_data):\n",
    "        X = X.view(batch_size, 0)\n",
    "        y_oh = y.view(batch_size, 0)\n",
    "        loss, acc, *model_params = training_plan.torchscript(\n",
    "            X, y_oh, th.tensor(batch_size), th.tensor(lr), model_params\n",
    "        )\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(acc.item())\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(\"Batch %d, loss: %f, accuracy: %f\" % (batch_idx, loss, acc))\n",
    "        if batch_idx >= max_updates:\n",
    "            break\n",
    "\n",
    "    job.report(model_params)\n",
    "    # Save losses/accuracies from cycle\n",
    "    cycles_log.append((losses, accuracies))\n",
    "\n",
    "# Called when the client is rejected from cycle\n",
    "def on_rejected(job: FLJob, timeout):\n",
    "    if timeout is None:\n",
    "        print(f\"Rejected from cycle without timeout (this means FL training is done)\")\n",
    "    else:\n",
    "        print(f\"Rejected from cycle with timeout: {timeout}\")\n",
    "    status[\"ended\"] = True\n",
    "\n",
    "# Called when error occured\n",
    "def on_error(job: FLJob, error: Exception):\n",
    "    print(f\"Error: {error}\")\n",
    "    status[\"ended\"] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyGrid Node address\n",
    "gridAddress = \"https://pygri-pygri-frtwp3inl2zq-2ea21a767266378c.elb.us-east-1.amazonaws.com:5000\"\n",
    "# Hosted model name/version\n",
    "model_name = \"perceptron\"\n",
    "model_version = \"2.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_job(self, model_name, model_version) -> FLJob:\n",
    "        if self.worker_id is None:\n",
    "            auth_response = self.grid_worker.authenticate(\n",
    "                self.auth_token, model_name, model_version\n",
    "            )\n",
    "            self.worker_id = auth_response[\"data\"][\"worker_id\"]\n",
    "\n",
    "        job = FLJob(\n",
    "            fl_client=self,\n",
    "            grid_worker=self.grid_worker,\n",
    "            model_name=model_name,\n",
    "            model_version=model_version,\n",
    "        )\n",
    "        return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_and_run_cycle():\n",
    "    client = FLClient(url=gridAddress, auth_token=None, verbose=True)\n",
    "    client.worker_id = client.grid_worker.authenticate(None,model_name,model_version)[\"data\"][\"worker_id\"]\n",
    "    job = client.new_job(model_name, model_version)\n",
    "\n",
    "    # Set event handlers\n",
    "    job.add_listener(job.EVENT_ACCEPTED, on_accepted)\n",
    "    job.add_listener(job.EVENT_REJECTED, on_rejected)\n",
    "    job.add_listener(job.EVENT_ERROR, on_error)\n",
    "\n",
    "    # Shoot!\n",
    "    job.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected from cycle without timeout (this means FL training is done)\n"
     ]
    }
   ],
   "source": [
    "while not status[\"ended\"]:\n",
    "    create_client_and_run_cycle()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(10, 10))\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "offset = 0\n",
    "for i, cycle_log in enumerate(cycles_log):\n",
    "    losses, accuracies = cycle_log\n",
    "    x = range(offset, offset + len(losses))\n",
    "    axs[0].plot(x, losses)\n",
    "    axs[1].plot(x, accuracies)\n",
    "    offset += len(losses)\n",
    "    print(f\"Cycle {i + 1}:\\tLoss: {np.mean(losses)}\\tAcc: {np.mean(accuracies)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysyft",
   "language": "python",
   "name": "pysyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
