{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Linear Model (predict BMI off of Height/Weight, should be a perfect regression!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import syft as sy\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex = sy.VirtualWorker(hook, id='alex')\n",
    "toby = sy.VirtualWorker(hook, id='toby')\n",
    "jake = sy.VirtualWorker(hook, id='jake')\n",
    "matt = sy.VirtualWorker(hook, id='matt')\n",
    "shreyas = sy.VirtualWorker(hook, id='shreyas')\n",
    "\n",
    "# secure worker node built as well for secure regression building\n",
    "secure_machine = sy.VirtualWorker(hook, id='secure_machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of making tensors, sending, making a grid\n",
    "\n",
    "# initiate tensors\n",
    "alex_data = torch.tensor([[21, 1, 3, 165, 71, 23]]).tag(\"#test2\")\n",
    "toby_data = torch.tensor([[19, 0, 1, 175, 73, 23]]).tag(\"#test2\")\n",
    "jake_data = torch.tensor([23, 1, 4, 123, 69, 18]).tag(\"#test2\")\n",
    "matt_data = torch.tensor([28, 0, 7, 137, 82, 14]).tag(\"#test2\")\n",
    "shreyas_data = torch.tensor([16, 1, 2, 167, 76, 20]).tag(\"#test2\")\n",
    "\n",
    "# Send the tensor to the right worker node\n",
    "alex_tensor = alex_data.send(alex)\n",
    "toby_tensor = toby_data.send(toby)\n",
    "jake_tensor = jake_data.send(jake)\n",
    "matt_tensor = matt_data.send(matt)\n",
    "shreyas_tensor = shreyas_data.send(shreyas)\n",
    "\n",
    "workers = [alex, toby, jake, matt, shreyas]\n",
    "grid = sy.PrivateGridNetwork(*workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_outcome_data = torch.tensor([[1]])\n",
    "toby_outcome_data = torch.tensor([[0]])\n",
    "jake_outcome_data = torch.tensor([[1]])\n",
    "matt_outcome_data = torch.tensor([[1]])\n",
    "shreyas_outcome_data = torch.tensor([[0]])\n",
    "\n",
    "alex_outcome = alex_outcome_data.send(alex)\n",
    "toby_outcome = toby_outcome_data.send(toby)\n",
    "jake_outcome = jake_outcome_data.send(jake)\n",
    "matt_outcome = matt_outcome_data.send(matt)\n",
    "shreyas_outcome = shreyas_outcome_data.send(shreyas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6821]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Linear(6, 1)\n",
    "abc = torch.randn(1,1)\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby loss: tensor(7.6816e+23)\n",
      "jake loss: tensor(1.3077e+20)\n",
      "alex loss: tensor(2.5488e+23)\n",
      "matt loss: tensor(9.7157e+20)\n",
      "shreyas loss: tensor(3.6741e+23)\n",
      "toby loss: tensor(inf)\n",
      "jake loss: tensor(inf)\n",
      "alex loss: tensor(inf)\n",
      "matt loss: tensor(inf)\n",
      "shreyas loss: tensor(inf)\n",
      "toby loss: tensor(inf)\n",
      "jake loss: tensor(inf)\n",
      "alex loss: tensor(inf)\n",
      "matt loss: tensor(inf)\n",
      "shreyas loss: tensor(inf)\n",
      "toby loss: tensor(nan)\n",
      "jake loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "matt loss: tensor(nan)\n",
      "shreyas loss: tensor(nan)\n",
      "toby loss: tensor(nan)\n",
      "jake loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "matt loss: tensor(nan)\n",
      "shreyas loss: tensor(nan)\n",
      "toby loss: tensor(nan)\n",
      "jake loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "matt loss: tensor(nan)\n",
      "shreyas loss: tensor(nan)\n",
      "toby loss: tensor(nan)\n",
      "jake loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "matt loss: tensor(nan)\n",
      "shreyas loss: tensor(nan)\n",
      "toby loss: tensor(nan)\n",
      "jake loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "matt loss: tensor(nan)\n",
      "shreyas loss: tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# modified from OpenMinded Pysyft Tutorial Part 04 - Federated Learning via a Trusted Aggregator\n",
    "def train_model(iterations, worker_iterations):\n",
    "    \n",
    "    for iterator in range(iterations):\n",
    "        \n",
    "        toby_model = model.copy().send(toby)\n",
    "        alex_model = model.copy().send(alex)\n",
    "        jake_model = model.copy().send(jake)\n",
    "        matt_model = model.copy().send(matt)\n",
    "        shreyas_model = model.copy().send(shreyas)\n",
    "        \n",
    "        # create optimizer functions\n",
    "        toby_opt = optim.SGD(params=toby_model.parameters(), lr=0.05)\n",
    "        alex_opt = optim.SGD(params=alex_model.parameters(), lr=0.05)\n",
    "        jake_opt = optim.SGD(params=jake_model.parameters(), lr=0.05)\n",
    "        matt_opt = optim.SGD(params=matt_model.parameters(), lr=0.05)\n",
    "        shreyas_opt = optim.SGD(params=shreyas_model.parameters(), lr=0.05)\n",
    "        \n",
    "        for wi in range(worker_iterations):\n",
    "            \n",
    "            # Train Toby's Model\n",
    "            toby_opt.zero_grad()\n",
    "            toby_pred = toby_model(toby_tensor.float())\n",
    "            toby_loss = ((toby_pred - toby_outcome)**2).sum()\n",
    "            toby_loss.backward()\n",
    "            \n",
    "            toby_opt.step()\n",
    "            toby_loss = toby_loss.get().data\n",
    "            \n",
    "            # Train Alex's Model\n",
    "            alex_opt.zero_grad()\n",
    "            alex_pred = alex_model(alex_tensor.float())\n",
    "            alex_loss = ((alex_pred - alex_outcome)**2).sum()\n",
    "            alex_loss.backward()\n",
    "            \n",
    "            alex_opt.step()\n",
    "            alex_loss = alex_loss.get().data\n",
    "            \n",
    "            # Train Jake's Model\n",
    "            jake_opt.zero_grad()\n",
    "            jake_pred = jake_model(jake_tensor.float())\n",
    "            jake_loss = ((jake_pred - jake_outcome)**2).sum()\n",
    "            jake_loss.backward()\n",
    "            \n",
    "            jake_opt.step()\n",
    "            jake_loss = jake_loss.get().data\n",
    "            \n",
    "            # Train Matt's Model\n",
    "            matt_opt.zero_grad()\n",
    "            matt_pred = matt_model(matt_tensor.float())\n",
    "            matt_loss = ((matt_pred - matt_outcome)**2).sum()\n",
    "            matt_loss.backward()\n",
    "            \n",
    "            matt_opt.step()\n",
    "            matt_loss = matt_loss.get().data\n",
    "            \n",
    "            # Train Shreyas's Model\n",
    "            shreyas_opt.zero_grad()\n",
    "            shreyas_pred = shreyas_model(shreyas_tensor.float())\n",
    "            shreyas_loss = ((shreyas_pred - shreyas_outcome)**2).sum()\n",
    "            shreyas_loss.backward()\n",
    "            \n",
    "            shreyas_opt.step()\n",
    "            shreyas_loss = shreyas_loss.get().data\n",
    "            \n",
    "        # move the model to secure worker\n",
    "        toby_model.move(secure_machine)\n",
    "        jake_model.move(secure_machine)\n",
    "        alex_model.move(secure_machine)\n",
    "        matt_model.move(secure_machine)\n",
    "        shreyas_model.move(secure_machine)\n",
    "                        \n",
    "        # set the weight and bias divided by number of models used\n",
    "        with torch.no_grad():\n",
    "            model.weight.set_(((toby_model.weight.data + jake_model.weight.data + alex_model.weight.data + matt_model.weight.data + shreyas_model.weight.data) / 5).get())\n",
    "            model.bias.set_(((toby_model.bias.data + jake_model.bias.data + alex_model.bias.data + matt_model.bias.data + shreyas_model.bias.data) / 5).get())\n",
    "            \n",
    "        # printing loss\n",
    "        print (\"toby loss: \" + str(toby_loss))\n",
    "        print (\"jake loss: \" + str(jake_loss))\n",
    "        print (\"alex loss: \" + str(alex_loss))\n",
    "        print (\"matt loss: \" + str(matt_loss))\n",
    "        print (\"shreyas loss: \" + str(shreyas_loss))\n",
    "        \n",
    "train_model(8, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "toby loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "toby loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "toby loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "toby loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "toby loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "toby loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "toby loss: tensor(nan)\n",
      "alex loss: tensor(nan)\n",
      "tensor([[nan]], grad_fn=<AddmmBackward>)\n",
      "(Wrapper)>[PointerTensor | me:26442319493 -> toby:77611184004]\n",
      "tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# modified from OpenMinded Pysyft Tutorial Part 04 - Federated Learning via a Trusted Aggregator\n",
    "def train_model(iterations, worker_iterations):\n",
    "    \n",
    "    for iterator in range(iterations):\n",
    "        \n",
    "        toby_model = model.copy().send(toby)\n",
    "        alex_model = model.copy().send(alex)\n",
    "        \n",
    "        # create optimizer functions\n",
    "        toby_opt = optim.SGD(params=toby_model.parameters(), lr=0.15)\n",
    "        alex_opt = optim.SGD(params=alex_model.parameters(), lr=0.15)\n",
    "        \n",
    "        for wi in range(worker_iterations):\n",
    "            \n",
    "            # Train Toby's Model\n",
    "            toby_opt.zero_grad()\n",
    "            toby_pred = toby_model(toby_tensor.float())\n",
    "            toby_loss = ((toby_pred - toby_outcome)**2).sum()\n",
    "            toby_loss.backward()\n",
    "            \n",
    "            toby_opt.step()\n",
    "            toby_loss = toby_loss.get().data\n",
    "            \n",
    "            # Train Alex's Model\n",
    "            alex_opt.zero_grad()\n",
    "            alex_pred = alex_model(alex_tensor.float())\n",
    "            alex_loss = ((alex_pred - alex_outcome)**2).sum()\n",
    "            alex_loss.backward()\n",
    "            \n",
    "            alex_opt.step()\n",
    "            alex_loss = alex_loss.get().data\n",
    "            \n",
    "            \n",
    "        # move the model to secure worker\n",
    "        toby_model.move(secure_machine)\n",
    "        alex_model.move(secure_machine)\n",
    "                        \n",
    "        # set the weight and bias divided by number of models used\n",
    "        with torch.no_grad():\n",
    "            model.weight.set_(((toby_model.weight.data + alex_model.weight.data) / 2).get())\n",
    "            model.bias.set_(((toby_model.bias.data + alex_model.bias.data) / 2).get())\n",
    "            \n",
    "        # printing loss\n",
    "        print (\"toby loss: \" + str(toby_loss.data))\n",
    "        print (\"alex loss: \" + str(alex_loss.data))\n",
    "        \n",
    "train_model(8, 4)\n",
    "\n",
    "# this can see how well the model worked\n",
    "predictions = model(alex_data.float())\n",
    "loss = ((predictions - toby_outcome_data) ** 2).sum()\n",
    "print(predictions)\n",
    "print(toby_outcome)\n",
    "print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysyft",
   "language": "python",
   "name": "pysyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
