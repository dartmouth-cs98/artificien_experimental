{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Neccesary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x12334cad0>"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import syft as sy\n",
    "from syft.serde import protobuf\n",
    "from syft_proto.execution.v1.plan_pb2 import Plan as PlanPB\n",
    "from syft_proto.execution.v1.state_pb2 import State as StatePB\n",
    "from syft.grid.clients.model_centric_fl_client import ModelCentricFLClient\n",
    "from syft.execution.state import State\n",
    "from syft.execution.placeholder import PlaceHolder\n",
    "from syft.execution.translation import TranslationTarget\n",
    "\n",
    "import torch as th\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "from websocket import create_connection\n",
    "import websockets\n",
    "import json\n",
    "import requests\n",
    "\n",
    "sy.make_hook(globals())\n",
    "hook.local_worker.framework = None # force protobuf serialization for tensors\n",
    "th.random.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_params(module, params_list, start_param_idx=0):\n",
    "    \"\"\" Set params list into model recursively\n",
    "    \"\"\"\n",
    "    param_idx = start_param_idx\n",
    "\n",
    "    for name, param in module._parameters.items():\n",
    "        module._parameters[name] = params_list[param_idx]\n",
    "        param_idx += 1\n",
    "\n",
    "    for name, child in module._modules.items():\n",
    "        if child is not None:\n",
    "            param_idx = set_model_params(child, params_list, param_idx)\n",
    "\n",
    "    return param_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define A Model \n",
    "### - A perceptron (for a linear regression)\n",
    "\n",
    "We want a simple model that will allow us to test the deployment of a model via pygrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(th.nn.Module):    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = th.nn.Linear(3, 1)    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "    \n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[3, 1]"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param.nelement() for param in model.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the training Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_with_logits(logits, targets, batch_size):\n",
    "    \"\"\" Calculates softmax entropy\n",
    "        Args:\n",
    "            * logits: (NxC) outputs of dense layer\n",
    "            * targets: (NxC) one-hot encoded labels\n",
    "            * batch_size: value of N, temporarily required because Plan cannot trace .shape\n",
    "    \"\"\"\n",
    "    return (logits - targets).sum() / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_sgd(param, **kwargs):\n",
    "    return param - kwargs['lr'] * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.func2plan()\n",
    "def training_plan(X, y, batch_size, lr, model_params):\n",
    "    # inject params into model\n",
    "    set_model_params(model, model_params)\n",
    "\n",
    "    # forward pass\n",
    "    logits = model.forward(X)\n",
    "    \n",
    "    # loss\n",
    "    loss = mse_with_logits(logits, y, batch_size)\n",
    "    \n",
    "    # backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # step\n",
    "    updated_params = [\n",
    "        naive_sgd(param, lr=lr)\n",
    "        for param in model_params\n",
    "    ]\n",
    "    \n",
    "    # accuracy\n",
    "    pred = th.argmax(logits, dim=1)\n",
    "    target = th.argmax(y, dim=1)\n",
    "    acc = pred.eq(target).sum().float() / batch_size\n",
    "\n",
    "    return (\n",
    "        loss,\n",
    "        acc,\n",
    "        *updated_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy input parameters to make the trace\n",
    "model_params = [param.data for param in model.parameters()]  # raw tensors instead of nn.Parameter\n",
    "\n",
    "X = th.randn(1, 3)\n",
    "y = nn.functional.one_hot(th.tensor([2]))\n",
    "\n",
    "lr = th.tensor([0.2])\n",
    "batch_size = th.tensor([3])\n",
    "\n",
    "_ = training_plan.build(X, y, batch_size, lr, model_params, trace_autograd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 1], m2: [3 x 1] at ../aten/src/TH/generic/THTensorMath.cpp:136",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-144-6df07a0c9880>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mbatch_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mth\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtraining_plan\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel_params\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrace_autograd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/execution/plan.py\u001B[0m in \u001B[0;36mbuild\u001B[0;34m(self, trace_autograd, *args)\u001B[0m\n\u001B[1;32m    271\u001B[0m                 \u001B[0mframework_kwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mf_name\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwrap_framework_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrole\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 273\u001B[0;31m         \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mframework_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    274\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    275\u001B[0m         \u001B[0;31m# Register inputs in role\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-142-568facdcd4c6>\u001B[0m in \u001B[0;36mtraining_plan\u001B[0;34m(X, y, batch_size, lr, model_params)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;31m# forward pass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mlogits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0;31m# loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-138-3839077483cf>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m         \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    530\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    531\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 532\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    533\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    534\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 87\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     88\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     89\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py\u001B[0m in \u001B[0;36moverloaded_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    333\u001B[0m                 \u001B[0mhandle_func_command\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msyft\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mframework\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle_func_command\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    334\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 335\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhandle_func_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    336\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    337\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py\u001B[0m in \u001B[0;36mhandle_func_command\u001B[0;34m(cls, command)\u001B[0m\n\u001B[1;32m    292\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcmd\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 294\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mcmd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    295\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    296\u001B[0m         \u001B[0;31m# Replace all AutogradTensor with their child attribute\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    252\u001B[0m                     \u001B[0mUn\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mhook\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mfunction\u001B[0m \u001B[0mto\u001B[0m \u001B[0mhave\u001B[0m \u001B[0mits\u001B[0m \u001B[0mdetailed\u001B[0m \u001B[0mbehaviour\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    253\u001B[0m                     \"\"\"\n\u001B[0;32m--> 254\u001B[0;31m                     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunctional\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnative_linear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    255\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    256\u001B[0m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlinear\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1368\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbias\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1369\u001B[0m         \u001B[0;31m# fused op is marginally faster\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1370\u001B[0;31m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maddmm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1371\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1372\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py\u001B[0m in \u001B[0;36moverloaded_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    333\u001B[0m                 \u001B[0mhandle_func_command\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msyft\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mframework\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle_func_command\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    334\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 335\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhandle_func_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    336\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    337\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/execution/placeholder.py\u001B[0m in \u001B[0;36mhandle_func_command\u001B[0;34m(cls, command)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m         \u001B[0;31m# Send it to the appropriate class and get the response\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 71\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnew_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle_func_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_command\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     72\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m         \u001B[0;31m# Find first placeholder in args\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py\u001B[0m in \u001B[0;36mhandle_func_command\u001B[0;34m(cls, command)\u001B[0m\n\u001B[1;32m    292\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcmd\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 294\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mcmd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    295\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    296\u001B[0m         \u001B[0;31m# Replace all AutogradTensor with their child attribute\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py\u001B[0m in \u001B[0;36maddmm\u001B[0;34m(bias, input_tensor, weight)\u001B[0m\n\u001B[1;32m    233\u001B[0m                 \u001B[0minput_tensor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAutogradTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequires_grad\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_tensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwrap\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 235\u001B[0;31m             \u001B[0mmatmul\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput_tensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    236\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py\u001B[0m in \u001B[0;36mmethod_with_grad\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    161\u001B[0m                 )\n\u001B[1;32m    162\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 163\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_self\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mnew_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mnew_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    164\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    165\u001B[0m                 \u001B[0;31m# Put back SyftTensor on the tensors found in the response\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/tensors.py\u001B[0m in \u001B[0;36mtracing_method\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    174\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcreate_tracing_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase_method\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    175\u001B[0m             \u001B[0;32mdef\u001B[0m \u001B[0mtracing_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 176\u001B[0;31m                 \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbase_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    177\u001B[0m                 \u001B[0mcommand\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    178\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtracing\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py\u001B[0m in \u001B[0;36moverloaded_syft_method\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m             \u001B[0;31m# Send it to the appropriate class and get the response\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_self\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mnew_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mnew_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    112\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m             \u001B[0;31m# For inplace methods, just directly return self\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py\u001B[0m in \u001B[0;36moverloaded_native_method\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    167\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m                     \u001B[0;31m# we can make some errors more descriptive with this method\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 169\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mroute_method_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    170\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    171\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# means that there is a wrapper to remove\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py\u001B[0m in \u001B[0;36moverloaded_native_method\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    164\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 165\u001B[0;31m                     \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    166\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: size mismatch, m1: [1 x 1], m2: [3 x 1] at ../aten/src/TH/generic/THTensorMath.cpp:136"
     ]
    }
   ],
   "source": [
    "model_params = [param.data for param in model.parameters()]  # raw tensors instead of nn.Parameter\n",
    "X = th.randn(1, 1)\n",
    "y = nn.functional.one_hot(th.tensor([2]))\n",
    "lr = th.tensor([0.2])\n",
    "batch_size = th.tensor([3])\n",
    "\n",
    "_ = training_plan.build(X, y, batch_size, lr, model_params, trace_autograd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.func2plan()\n",
    "def avg_plan(avg, item, num):\n",
    "    new_avg = []\n",
    "    for i, param in enumerate(avg):\n",
    "        new_avg.append((avg[i] * num + item[i]) / (num + 1))\n",
    "    return new_avg\n",
    "\n",
    "# Build the Plan\n",
    "_ = avg_plan.build(model_params, model_params, th.tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridAddress = \"pygri-pygri-frtwp3inl2zq-2ea21a767266378c.elb.us-east-1.amazonaws.com:5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyGrid Node address\n",
    "\n",
    "grid = ModelCentricFLClient(id=\"test\", address=gridAddress, secure=False)\n",
    "grid.connect() # These name/version you use in worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"perceptron\" \n",
    "version = \"1.0\"\n",
    "\n",
    "client_config = {\n",
    "    \"name\": name,\n",
    "    \"version\": version,\n",
    "    \"batch_size\": 1,\n",
    "    \"lr\": 0.2,\n",
    "    \"max_updates\": 100  # custom syft.js option that limits number of training loops per worker\n",
    "}\n",
    "\n",
    "server_config = {\n",
    "    \"min_workers\": 1,\n",
    "\n",
    "    \"max_workers\": 5,\n",
    "    \"pool_selection\": \"random\",\n",
    "    \"do_not_reuse_workers_until_cycle\": 6,\n",
    "    \"cycle_length\": 28800,  # max cycle length in seconds\n",
    "    \"num_cycles\": 5,  # max number of cycles\n",
    "    \"max_diffs\": 1,  # number of diffs to collect before avg\n",
    "    \"minimum_upload_speed\": 0,\n",
    "    \"minimum_download_speed\": 0,\n",
    "    \"iterative_plan\": True  # tells PyGrid that avg plan is executed per diff\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_state = State(\n",
    "    state_placeholders=[\n",
    "        PlaceHolder().instantiate(param)\n",
    "        for param in model_params\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = grid.host_federated_training(\n",
    "    model=model_params_state,\n",
    "    client_plans={'training_plan': training_plan},\n",
    "    client_protocols={},\n",
    "    server_averaging_plan=avg_plan,\n",
    "    client_config=client_config,\n",
    "    server_config=server_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Host response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}